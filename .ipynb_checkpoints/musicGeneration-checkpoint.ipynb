{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f548003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D850_1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D850_2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D850_3.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D850_4.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D935_1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D935_2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D935_3.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schubert_D935_4.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d760_1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d760_2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d760_3.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d760_4.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d960_1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d960_2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d960_3.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schub_d960_4.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schuim-1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schuim-2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schuim-3.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schuim-4.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schumm-1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schumm-2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schumm-3.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schumm-4.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schumm-5.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schumm-6.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schu_143_1.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schu_143_2.mid\n",
      "Loading Music File: C:\\Users\\lenovo\\Desktop\\piano/schu_143_3.mid\n",
      "308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "#library for understanding music\n",
    "from music21 import *\n",
    "\n",
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chor\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)\n",
    "\n",
    "\n",
    "\n",
    "#specify the path\n",
    "path=r'C:\\Users\\lenovo\\Desktop\\piano/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])\n",
    "\n",
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc56557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([186.,  46.,  27.,  10.,   4.,   6.,   6.,  12.,   8.,   3.]),\n",
       " array([1.0000e+00, 1.7290e+02, 3.4480e+02, 5.1670e+02, 6.8860e+02,\n",
       "        8.6050e+02, 1.0324e+03, 1.2043e+03, 1.3762e+03, 1.5481e+03,\n",
       "        1.7200e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 324
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59f6999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fecaa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)\n",
    "\n",
    "\n",
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x,dtype=\"object\")\n",
    "y=np.array(y,dtype=\"object\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
    "\n",
    "\n",
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)\n",
    "\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)\n",
    "\n",
    "\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5a177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4883a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944a3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80d973af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "503/503 [==============================] - 36s 70ms/step - loss: 4.5717 - val_loss: 4.0253\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.02529, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 3.8137 - val_loss: 3.8178\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.02529 to 3.81781, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 3.6187 - val_loss: 3.6626\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.81781 to 3.66256, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.4700 - val_loss: 3.5530\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.66256 to 3.55297, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.3736 - val_loss: 3.4715\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.55297 to 3.47155, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 3.2956 - val_loss: 3.4328\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.47155 to 3.43278, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.2169 - val_loss: 3.3558\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.43278 to 3.35577, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.1555 - val_loss: 3.3283\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.35577 to 3.32826, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 3.1045 - val_loss: 3.2868\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.32826 to 3.28678, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "503/503 [==============================] - 33s 65ms/step - loss: 3.0499 - val_loss: 3.2523\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.28678 to 3.25232, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.0091 - val_loss: 3.2381\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.25232 to 3.23807, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "503/503 [==============================] - 37s 73ms/step - loss: 2.9730 - val_loss: 3.1868\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.23807 to 3.18681, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.9371 - val_loss: 3.1662\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.18681 to 3.16624, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "503/503 [==============================] - 35s 70ms/step - loss: 2.9086 - val_loss: 3.1447\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.16624 to 3.14468, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "503/503 [==============================] - 35s 70ms/step - loss: 2.8763 - val_loss: 3.1374\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.14468 to 3.13743, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.8497 - val_loss: 3.1185\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.13743 to 3.11849, saving model to best_model.h5\n",
      "Epoch 17/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.8165 - val_loss: 3.0882\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.11849 to 3.08825, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "503/503 [==============================] - 36s 72ms/step - loss: 2.7974 - val_loss: 3.0877\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.08825 to 3.08770, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 2.7749 - val_loss: 3.0403\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.08770 to 3.04027, saving model to best_model.h5\n",
      "Epoch 20/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.7616 - val_loss: 3.0335\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.04027 to 3.03346, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "503/503 [==============================] - 34s 69ms/step - loss: 2.7354 - val_loss: 3.0506\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.03346\n",
      "Epoch 22/50\n",
      "503/503 [==============================] - 36s 72ms/step - loss: 2.7069 - val_loss: 3.0128\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.03346 to 3.01283, saving model to best_model.h5\n",
      "Epoch 23/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.7086 - val_loss: 3.0079\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.01283 to 3.00790, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "503/503 [==============================] - 37s 74ms/step - loss: 2.6786 - val_loss: 2.9903\n",
      "\n",
      "Epoch 00024: val_loss improved from 3.00790 to 2.99030, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "503/503 [==============================] - 36s 71ms/step - loss: 2.6686 - val_loss: 2.9877\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.99030 to 2.98772, saving model to best_model.h5\n",
      "Epoch 26/50\n",
      "503/503 [==============================] - 37s 73ms/step - loss: 2.6494 - val_loss: 2.9803\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.98772 to 2.98030, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "503/503 [==============================] - 35s 70ms/step - loss: 2.6393 - val_loss: 2.9680\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.98030 to 2.96799, saving model to best_model.h5\n",
      "Epoch 28/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.6234 - val_loss: 2.9715\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.96799\n",
      "Epoch 29/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.6111 - val_loss: 2.9491\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.96799 to 2.94906, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "503/503 [==============================] - 36s 71ms/step - loss: 2.6012 - val_loss: 2.9335\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.94906 to 2.93348, saving model to best_model.h5\n",
      "Epoch 31/50\n",
      "503/503 [==============================] - 36s 72ms/step - loss: 2.5956 - val_loss: 2.9304\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.93348 to 2.93042, saving model to best_model.h5\n",
      "Epoch 32/50\n",
      "503/503 [==============================] - 35s 70ms/step - loss: 2.5944 - val_loss: 2.9124\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.93042 to 2.91240, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.5645 - val_loss: 2.9198\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.91240\n",
      "Epoch 34/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 2.5479 - val_loss: 2.9099\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.91240 to 2.90988, saving model to best_model.h5\n",
      "Epoch 35/50\n",
      "503/503 [==============================] - 36s 71ms/step - loss: 2.5523 - val_loss: 2.9166\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.90988\n",
      "Epoch 36/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.5392 - val_loss: 2.8995\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.90988 to 2.89951, saving model to best_model.h5\n",
      "Epoch 37/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.5288 - val_loss: 2.9078\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.89951\n",
      "Epoch 38/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.5283 - val_loss: 2.9052\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.89951\n",
      "Epoch 39/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.5197 - val_loss: 2.8987\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.89951 to 2.89866, saving model to best_model.h5\n",
      "Epoch 40/50\n",
      "503/503 [==============================] - 35s 70ms/step - loss: 2.5072 - val_loss: 2.8885\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.89866 to 2.88855, saving model to best_model.h5\n",
      "Epoch 41/50\n",
      "503/503 [==============================] - 37s 73ms/step - loss: 2.5088 - val_loss: 2.8877\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.88855 to 2.88772, saving model to best_model.h5\n",
      "Epoch 42/50\n",
      "503/503 [==============================] - 35s 70ms/step - loss: 2.5015 - val_loss: 2.8792\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.88772 to 2.87924, saving model to best_model.h5\n",
      "Epoch 43/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.4867 - val_loss: 2.8776\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.87924 to 2.87762, saving model to best_model.h5\n",
      "Epoch 44/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.4887 - val_loss: 2.8653\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.87762 to 2.86526, saving model to best_model.h5\n",
      "Epoch 45/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.4696 - val_loss: 2.8626\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.86526 to 2.86262, saving model to best_model.h5\n",
      "Epoch 46/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 2.4748 - val_loss: 2.8536\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.86262 to 2.85364, saving model to best_model.h5\n",
      "Epoch 47/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.4657 - val_loss: 2.8436\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.85364 to 2.84359, saving model to best_model.h5\n",
      "Epoch 48/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.4502 - val_loss: 2.8371\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.84359 to 2.83715, saving model to best_model.h5\n",
      "Epoch 49/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.4521 - val_loss: 2.8448\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.83715\n",
      "Epoch 50/50\n",
      "503/503 [==============================] - 35s 69ms/step - loss: 2.4499 - val_loss: 2.8383\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.83715\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08470999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a61e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 37, 37, 98, 37, 37, 37, 37, 37, 37]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b68d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "868c4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ec72527",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b223019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3468713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e220e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
